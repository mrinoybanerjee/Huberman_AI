{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HubermanAI: Using RAG Based LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MONGODB_CONNECTION_STRING = os.getenv(\"MONGODB_URI\")\n",
    "MONGODB_DATABASE = os.getenv(\"MONGODB_DATABASE\")\n",
    "MONGODB_COLLECTION = os.getenv(\"MONGODB_COLLECTION\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction from Newsletter PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to preprocess and clean text\n",
    "def preprocess_text_mupdf(text):\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove empty lines\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:!?()\\'\\\"\\n]+', ' ', text)  # Remove special characters but keep punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()\n",
    "\n",
    "# Extract the ZIP file\n",
    "raw_path = '/Users/mrinoyb2/git/Huberman_AI/Data/Raw/Newsletters'\n",
    "clean_text_dir = '/Users/mrinoyb2/git/Huberman_AI/Data/Clean'\n",
    "os.makedirs(clean_text_dir, exist_ok=True)\n",
    "\n",
    "# Process each PDF file in the extracted directory\n",
    "for root, dirs, files in os.walk(raw_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "            cleaned_text_mupdf = \"\"\n",
    "            for page_number in range(pdf_document.page_count):\n",
    "                page = pdf_document.load_page(page_number)\n",
    "                text = page.get_text()\n",
    "                cleaned_text_mupdf += preprocess_text_mupdf(text)\n",
    "\n",
    "            pdf_document.close()\n",
    "\n",
    "            # Save the cleaned text to a corresponding file\n",
    "            clean_text_path = os.path.join(clean_text_dir, os.path.splitext(file)[0] + '.txt')\n",
    "            with open(clean_text_path, 'w') as file:\n",
    "                file.write(cleaned_text_mupdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks in MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks stored in MongoDB: 1402\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymongo\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to chunk text by sentence\n",
    "def chunk_by_sentence(text):\n",
    "    sentences = []\n",
    "    tmp_sentence = \"\"\n",
    "    for char in text:\n",
    "        if char in [\".\", \"!\", \"?\"]:\n",
    "            if tmp_sentence:  # Check if tmp_sentence is not empty\n",
    "                sentences.append(tmp_sentence.strip())\n",
    "            tmp_sentence = \"\"\n",
    "        else:\n",
    "            tmp_sentence += char\n",
    "    if tmp_sentence:\n",
    "        sentences.append(tmp_sentence.strip())\n",
    "    return sentences\n",
    "\n",
    "# Path to the directory containing cleaned text files\n",
    "clean_text_dir = '/Users/mrinoyb2/git/Huberman_AI/Data/Clean'\n",
    "\n",
    "# Initialize a counter for unique MongoDB document IDs\n",
    "doc_id = 0\n",
    "\n",
    "# Iterate through each cleaned text file\n",
    "for file_name in os.listdir(clean_text_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(clean_text_dir, file_name)\n",
    "\n",
    "        # Read the cleaned text from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            cleaned_text = file.read()\n",
    "\n",
    "        # Chunk the text\n",
    "        chunks = chunk_by_sentence(cleaned_text)\n",
    "\n",
    "        # Store chunks in MongoDB\n",
    "        for chunk in chunks:\n",
    "            # Create a document for each chunk\n",
    "            document = {\"_id\": doc_id, \"text\": chunk}\n",
    "            # Insert the document into the collection\n",
    "            collection.insert_one(document)\n",
    "            # Increment the doc_id for the next document\n",
    "            doc_id += 1\n",
    "\n",
    "print(f\"Total chunks stored in MongoDB: {doc_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 0, 'text': '2 9 24, 5:29 PM Using Light for Health Huberman Lab https: www', 'embedding': [0.010065763257443905, 0.035282932221889496, 0.028818778693675995, 0.026955274865031242, 0.01648271083831787, 0.011640910990536213, -0.06494922935962677, 0.11319206655025482, -0.018184807151556015, -0.02461913414299488, 0.03490740805864334, -0.07955818623304367, -0.022448420524597168, 0.03251931816339493, -0.01984049193561077, 0.012255336157977581, 0.027136635035276413, -0.06925879418849945, -0.011622056365013123, -0.04784955829381943, 0.029384875670075417, -0.07974876463413239, 0.03966246172785759, -0.009871341288089752, -0.009696471504867077, 0.02612525224685669, 0.04401188716292381, -0.023275313898921013, 0.032688628882169724, 0.0033545251935720444, 0.0057613360695540905, -0.007797398138791323, 0.014110002666711807, 0.0008334319572895765, -0.03793388977646828, -0.02648104541003704, 0.059215012937784195, -0.04552782326936722, 0.0017140635754913092, 0.03357124701142311, 0.021113257855176926, -0.11704743653535843, 0.029895542189478874, -0.002939570927992463, 0.0021138684824109077, 0.06051287055015564, -0.007401456590741873, -0.029752330854535103, 0.008124344982206821, 0.043593745678663254, -0.08442571759223938, -0.019268710166215897, 0.027680298313498497, -0.03161865100264549, 0.07840537279844284, 0.08931468427181244, -0.05620940402150154, -0.0034841124434024096, 0.1047561839222908, -0.030377468094229698, 0.06419355422258377, 0.05893062800168991, -0.12109475582838058, 0.014394259080290794, 0.050590839236974716, 0.022628720849752426, -0.12095996737480164, -0.03134879097342491, 0.03391937166452408, -0.030626067891716957, -0.0187793280929327, -0.011649088934063911, 0.09243743121623993, -0.04693284630775452, -0.04767083376646042, -0.004966555628925562, -0.01204152125865221, -0.0474114790558815, 0.014219881035387516, -0.06670846045017242, 0.02925296686589718, -0.03450588881969452, 0.0023232195526361465, 0.1385149508714676, 0.04738318547606468, 0.000851402641274035, 0.047303520143032074, 0.19947105646133423, 0.004008252639323473, -0.059425387531518936, 0.01213786005973816, 0.04726544767618179, -0.0990818664431572, 0.016396306455135345, -0.08627357333898544, -0.005989609751850367, 0.029579684138298035, -0.01934005133807659, 0.004243623930960894, 0.018961729481816292, -0.0012440282152965665, -0.010091353207826614, -0.04877522215247154, 0.022749952971935272, -0.01772727258503437, -0.03634202480316162, -0.0731828585267067, 0.09789270162582397, -0.014768904075026512, -0.015026031993329525, 0.05540336295962334, -0.006918291095644236, -0.03404019773006439, -0.07801229506731033, 0.056330472230911255, 0.0738973543047905, 0.05095265433192253, -0.010469917207956314, 0.044534068554639816, -0.0017784987576305866, 0.05435959994792938, 0.03698047623038292, 0.01609497331082821, -0.06790698319673538, -0.005659267771989107, 0.04667733237147331, 0.07566043734550476, 2.7027935896945463e-33, 0.01418954785913229, -0.08438047766685486, -0.016403300687670708, 0.019101396203041077, 0.04677947610616684, -0.01875925436615944, -0.06362104415893555, 0.010580763220787048, -0.022347621619701385, -0.03171312063932419, -0.05336599424481392, -0.024746639654040337, -0.04785957187414169, -0.07261984795331955, -0.08543220162391663, -0.09711843729019165, 0.1130378395318985, 0.041125331073999405, -0.008804308250546455, 0.0072903200052678585, -0.04636329412460327, -0.11227831244468689, -0.029874030500650406, 0.04617179185152054, 0.021858960390090942, 0.02181291952729225, 0.025092968717217445, -0.03670584782958031, 0.06815798580646515, 0.031667422503232956, 0.032889727503061295, 0.04060746729373932, -0.041258152574300766, 0.03166443854570389, 0.0028076472226530313, 0.021640734747052193, -0.05604634806513786, 0.001099670073017478, -0.02242339961230755, -0.03574278578162193, 0.027777109295129776, 0.05445230379700661, 0.06318534165620804, -0.08669902384281158, 0.06409641355276108, 0.034058623015880585, -0.016652647405862808, 0.010137408040463924, 0.10301992297172546, 0.025455089285969734, -0.041366808116436005, 0.01008144672960043, -0.005864580161869526, -0.038679495453834534, 0.019799191504716873, 0.09828227758407593, 0.013090014457702637, -0.005819481797516346, -0.05084788799285889, 0.07028958201408386, 0.09612388163805008, 0.07378493994474411, -0.002010793425142765, -0.12074397504329681, 0.006156197749078274, -0.028668295592069626, -0.05601011961698532, -0.022676333785057068, -0.021084748208522797, 0.018983222544193268, -0.009644215926527977, 0.042440157383680344, 0.066635861992836, -0.07677718251943588, 0.02514396421611309, 0.03898162022233009, 0.05077074468135834, -0.012556280940771103, -0.05424349755048752, 0.05577484518289566, 0.026819469407200813, -0.01712251454591751, 0.0342019759118557, -0.038485102355480194, -0.026425661519169807, -0.009402482770383358, -0.04102768748998642, 0.06412406265735626, -0.08133940398693085, -0.03281506523489952, -0.040236879140138626, 0.004125118721276522, 0.044003233313560486, 0.031282104551792145, -0.09843761473894119, -2.494473950209759e-33, 0.03431171178817749, -0.013776766136288643, -0.0654798224568367, 0.06974051147699356, 0.11598613113164902, 0.0069273728877305984, 0.03963678330183029, 0.06583921611309052, 0.07451782375574112, 0.13367949426174164, 0.11388304829597473, -0.0070420801639556885, -0.06380786746740341, -0.060937125235795975, -0.012891617603600025, 0.020597172901034355, 0.0013470045523718, -0.01906346157193184, -0.06252125650644302, -0.027191681787371635, -0.06772399693727493, 0.06343742460012436, -0.044372767210006714, -0.04037880897521973, 0.0006334375939331949, 0.04988233745098114, 0.05455178767442703, 0.014292135834693909, -0.02785252220928669, -0.0013463530922308564, -0.12117088586091995, -0.0283892210572958, -0.012711095623672009, 0.059213533997535706, -0.011663638986647129, 0.04504784941673279, 0.04793917387723923, -0.02816983498632908, -0.037364277988672256, -0.020643949508666992, 0.039799243211746216, 0.0256531722843647, -0.08917989581823349, 0.006891798228025436, -0.06273194402456284, 0.07006854563951492, -0.002599670784547925, -0.025735607370734215, -0.06833093613386154, 0.027835816144943237, 0.040188953280448914, -0.06489350646734238, -0.08755315840244293, 0.002164596226066351, -0.013726982288062572, 0.014730031602084637, 0.04787605628371239, -0.01827402412891388, -0.028276624158024788, 0.027428366243839264, 0.002699011005461216, -0.01826670952141285, -0.06708292663097382, 0.05934640020132065, -0.005892917979508638, 0.0013298426056280732, 0.05467991530895233, 0.08575703948736191, -0.005220553372055292, -0.010175460018217564, 0.06827433407306671, 0.007099516689777374, -0.014357015490531921, -0.004625772126019001, -0.009188191033899784, -0.05179322883486748, 0.03673763945698738, 0.06869658827781677, -0.05335552617907524, -0.0009109650854952633, 0.03120083548128605, -0.08352182060480118, 0.020714785903692245, 0.0005493122152984142, -0.03753234073519707, -0.0447685532271862, 0.085479736328125, 0.009157913736999035, -0.030826494097709656, -0.015148548409342766, -0.045261308550834656, 0.08798974007368088, -0.08203507214784622, 0.031689342111349106, 0.030099786818027496, -2.0683719625935737e-08, 0.07288796454668045, -0.06404262036085129, -0.05836641043424606, -0.03310741111636162, -0.0007120240479707718, -0.05915302038192749, 0.04041437432169914, 0.02745545096695423, -0.006142180413007736, 0.09410231560468674, -0.0007894919253885746, -0.0017591837095096707, 0.010847528465092182, 0.005431260447949171, -0.0030922999139875174, 0.010027752257883549, -0.003540999721735716, -0.022212810814380646, -0.01900526136159897, -0.09788797050714493, -0.01367458887398243, -0.05629490315914154, 0.07827919721603394, -0.007307402323931456, -0.007314038462936878, 0.09099766612052917, -0.06303543597459793, 0.06726370751857758, 0.006639884784817696, 0.04440334439277649, 0.08735384792089462, 0.05952475219964981, -0.022082123905420303, -0.07215435802936554, -0.060011979192495346, -0.06603217869997025, -0.09472588449716568, -0.039734866470098495, -0.017693279311060905, 0.1459474265575409, -0.01574181765317917, -0.020840873941779137, -0.11523367464542389, 0.005823411513119936, 0.023838864639401436, -0.022864269092679024, 0.021121950820088387, -0.02582578919827938, -0.06952815502882004, 0.04945052042603493, -0.031889334321022034, -0.01458575390279293, 0.039671391248703, -0.08195307105779648, -0.01050366461277008, 0.006197626236826181, 0.051536981016397476, -0.060248296707868576, -0.0502607598900795, 0.007505446206778288, 0.11318787932395935, 0.0338694304227829, -0.036977771669626236, 0.010477416217327118]}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to update documents with embeddings\n",
    "def update_documents_with_embeddings():\n",
    "    for document in chunks_collection.find():\n",
    "        # Generate embedding\n",
    "        embedding = model.encode(document['text'], convert_to_tensor=False)\n",
    "        # Update document with embedding\n",
    "        chunks_collection.update_one({'_id': document['_id']}, {'$set': {'embedding': embedding.tolist()}})\n",
    "\n",
    "# Uncomment the following line to run the embedding update\n",
    "update_documents_with_embeddings()\n",
    "\n",
    "# Check the first document to see if the embedding was added\n",
    "print(chunks_collection.find_one())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (Score: 0.609): Episode 2 of the Huberman Lab Podcast JMaster Your Sleep) is all about that topic, but I wanted to provide a succinct list of the key things for sleep...\n",
      "Result 2 (Score: 0.567): See Newsletter 1 (Toolkit for Sleep) for details...\n",
      "Result 3 (Score: 0.557): As do most sleep medications...\n",
      "Result 4 (Score: 0.549): So whatever your life and goals and schedule, master your sleep...\n",
      "Result 5 (Score: 0.543): hubermanlab Follow Best nootropic: sleep Best stress relief: sleep Best trauma release: sleep Best immune booster: sleep Best hormone augmentation: sleep Best emotional stabilizer: sleep Sleep Tools: Ep...\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to perform semantic search\n",
    "def semantic_search(query, top_k=5):\n",
    "    # Generate query embedding\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = model.encode(query, convert_to_tensor=False)\n",
    "    \n",
    "    # Retrieve all embeddings from MongoDB and calculate similarity\n",
    "    similarities = []\n",
    "    for document in chunks_collection.find():\n",
    "        doc_embedding = np.array(document['embedding'])\n",
    "        similarity = 1 - cosine(query_embedding, doc_embedding)  # Higher score means more similar\n",
    "        similarities.append((document['_id'], similarity, document['text']))\n",
    "    \n",
    "    # Sort by similarity score in descending order\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_k most similar documents\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Example usage\n",
    "query = \"Best sleep protocol?\"\n",
    "results = semantic_search(query)\n",
    "for idx, (doc_id, similarity, text) in enumerate(results, start=1):\n",
    "    print(f\"Result {idx} (Score: {similarity:.3f}): {text}...\")  # Print the first 100 characters for brevity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Gemini Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an answer using RAG enabled LLama2 from Replicate\n",
    "def generate_RAG_answer(question, max_context_length=1000):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    context_results = semantic_search(question, top_k=1)\n",
    "    context = context_results[0][2]  # Get the text of the top result\n",
    "    # Truncate context if it exceeds the maximum length\n",
    "    if len(context) > max_context_length:\n",
    "        context = context[:max_context_length]\n",
    "\n",
    "    rag_prompt = f\"[INST]\\nQuestion: {question}\\nContext: {context}\\n[/INST]\"\n",
    "    print(rag_prompt)\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content(rag_prompt)\n",
    "    # return text part of the response\n",
    "    return response.text\n",
    "\n",
    "# Function to generate an answer using LLama2 from Replicate\n",
    "def generate_non_RAG_answer(question):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    non_rag_prompt = f\"[INST]\\nQuestion: {question}\\n[/INST]\"  # Fallback in case no context is found\n",
    "    print(non_rag_prompt)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content(non_rag_prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "Question: Best sleep protocol?\n",
      "Context: Episode 2 of the Huberman Lab Podcast JMaster Your Sleep) is all about that topic, but I wanted to provide a succinct list of the key things for sleep\n",
      "[/INST]\n",
      "**Best Sleep Protocol**\n",
      "\n",
      "* **Establish a regular sleep-wake cycle:** Go to bed and wake up around the same time each day, even on weekends.\n",
      "* **Create a relaxing bedtime routine:** Engage in activities that help you wind down before bed, such as taking a warm bath, reading, or listening to calming music.\n",
      "* **Optimize your sleep environment:** Ensure your bedroom is dark, quiet, and cool. Consider using blackout curtains, a white noise machine, and a fan for air circulation.\n",
      "* **Expose yourself to sunlight during the day:** Natural sunlight helps regulate your body's natural sleep-wake cycle. Aim for at least 30 minutes of sunlight exposure each morning.\n",
      "* **Avoid caffeine and alcohol before bed:** These substances can interfere with sleep.\n",
      "* **Make sure your bedroom is comfortable:** Use a supportive mattress and pillows that cradle your head and neck.\n",
      "* **Establish a 14-day sleep window:** Track your actual sleep times for 14 days and aim to stay within that range each night.\n",
      "* **Avoid napping too late in the day:** If you must nap, keep it short (20-30 minutes) and avoid napping after 3 pm.\n",
      "* **Manage stress and anxiety before bed:** Engage in relaxation techniques such as deep breathing, meditation, or yoga.\n",
      "* **Consider using a sleep supplement:** If necessary, consult with a healthcare professional to explore over-the-counter sleep aids or prescription medications.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Best sleep protocol?\"\n",
    "rag_answer = generate_RAG_answer(query)\n",
    "\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "Question: Best sleep protocol?\n",
      "[/INST]\n",
      "**Optimal Sleep Protocol**\n",
      "\n",
      "**Sleep Environment:**\n",
      "\n",
      "* **Dark:** Ensure the bedroom is as dark as possible by using blackout curtains or an eye mask.\n",
      "* **Cool:** Keep the temperature around 60-67°F (16-19°C).\n",
      "* **Quiet:** Use earplugs or a white noise machine to block out external noises.\n",
      "\n",
      "**Sleep-Wake Cycle:**\n",
      "\n",
      "* **Establish a regular sleep schedule:** Go to bed and wake up around the same time each day, even on weekends.\n",
      "* **Avoid late-night naps:** If you need a nap, keep it short (less than 30 minutes) and don't nap too close to bedtime.\n",
      "* **Get enough sunlight:** Exposure to natural light during the day helps regulate your sleep-wake cycle.\n",
      "\n",
      "**Bedtime Routine:**\n",
      "\n",
      "* **Wind down an hour before bed:** Engage in relaxing activities such as reading, taking a warm bath, or listening to calming music.\n",
      "* **Avoid caffeine and alcohol before bed:** Caffeine and alcohol can interfere with sleep.\n",
      "* **Create a bedtime ritual:** Perform the same calming activities every night before bed to signal your body it's time to sleep.\n",
      "\n",
      "**Sleep Hygiene:**\n",
      "\n",
      "* **Avoid nicotine before bed:** Nicotine is a stimulant that can keep you awake.\n",
      "* **Limit screen time before bed:** The blue light emitted from electronic devices can suppress melatonin production and make it harder to fall asleep.\n",
      "* **Exercise regularly:** Regular exercise can promote sleep, but avoid exercising too close to bedtime.\n",
      "\n",
      "**Sleep Position:**\n",
      "\n",
      "* **Back:** Sleeping on your back is generally the best position for supporting your spine and neck.\n",
      "* **Side:** If sleeping on your back is uncomfortable, sleeping on your side with a pillow between your knees can help align your spine.\n",
      "\n",
      "**Diet:**\n",
      "\n",
      "* **Eat a healthy diet:** Eating a balanced diet rich in fruits, vegetables, and whole grains can promote healthy sleep.\n",
      "* **Avoid heavy meals before bed:** Eating a large meal too close to bedtime can disrupt sleep.\n",
      "\n",
      "**Medical Considerations:**\n",
      "\n",
      "* **Rule out medical conditions:** Certain medical conditions, such as sleep apnea, can interfere with sleep. If you have persistent sleep problems, consult a healthcare professional.\n",
      "* **Consider sleep medication:** In some cases, sleep medication may be necessary to improve sleep quality. However, consult a healthcare professional before using any sleep medications.\n",
      "\n",
      "Remember, optimal sleep is a journey that requires consistency and effort over time. By following these guidelines and making lifestyle adjustments, you can improve your sleep quality and overall well-being.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Best sleep protocol?\"\n",
    "non_rag_answer = generate_non_RAG_answer(query)\n",
    "\n",
    "print(non_rag_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating RAG vs Non-RAG Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify this, I will take the following steps:\n",
    "1. Think of a query which has a well defined answer in the book.\n",
    "2. Find the true answer to a query from the actual source (book pdf). \n",
    "3. Then pass the query through the RAG based LLM and the regular LLM.\n",
    "4. Save both generated answers along with the true answer and find word embeddings for each. \n",
    "5. Finally, compare the word embeddings of the true answer with the RAG vs Non-RAG based LLM word embeddings using cosine similarity. \n",
    "\n",
    "Following these steps will help quantify the performace and accuracy of information in the two answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Best sleep protocol?\"\n",
    "\n",
    "# True Answer from the Huberman Lab Newsletter\n",
    "true_answer = \"\"\"1) View sunlight by going outside within 30-60 minutes of waking. Do that again in the late afternoon, prior to sunset. If you wake up before the sun is out and you want to be awake, turn on artificial lights and then go outside once the sun rises.\n",
    "\n",
    "On bright cloudless days: view morning and afternoon sun for 10 min; cloudy days: 20 min; very overcast days 30-60 min. If you live someplace with very minimal light, consider an artificial daytime simulator source.\n",
    "\n",
    "Don’t wear sunglasses for this practice if you safely can, but contact lenses and eyeglasses are fine.\n",
    "\n",
    "No, you don’t have to look directly at the sun, and never look at ANY light so bright it is painful to view! That said, you can’t wear a brimmed hat, sunglasses and remain in the shade and expect to “wake up” your circadian clock.\n",
    "​\n",
    "​2) Wake up at the same time each day and go to sleep when you first start to feel sleepy. Pushing through the sleepy late evening feeling and going to sleep too late (for you) is one reason people wake at 3 am and can’t fall back asleep.\n",
    "\n",
    "3) Avoid caffeine within 8-10 hours of bedtime. Dr. Matt Walker (sleep expert from UC Berkeley) might even say 12-14 hours. I do fine with caffeine at 2 pm and I go to sleep at ~10-11 pm. Dr. Walker was on the Huberman Lab Podcast and we discussed this in detail.\n",
    "\n",
    "4) If you have sleep disturbances, insomnia, or anxiety about sleep, try the research-supported protocols on the Reveri app (for iPhone). Do the Reveri sleep self-hypnosis 3x a week at any time of day. It’s only 10-15 min long and will help you rewire your nervous system to be able to relax faster.\n",
    "\n",
    "5) Avoid viewing bright lights—especially bright overhead lights between 10 pm and 4 am. Here is a simple rule: only use as much artificial lighting as is necessary for you to remain and move about safely at night. Blue blockers can help a bit at night but still dim the lights. Viewing bright lights of all colors are a problem for your circadian system. Candlelight and moonlight are fine. (Shift workers should see the Huberman Lab Podcast on jetlag for offsetting shift work negative effects. Same for jetlagged travelers.)\n",
    "\n",
    "6) Limit daytime naps to less than 90 min, or don’t nap at all. I love naps as do many of my colleagues. I tend to nap for 30 min most afternoons… maybe 45 min, but never longer.\n",
    "\n",
    "7) If you wake up in the middle of the night (which, by the way, is normal to do once or so each night) but you can’t fall back asleep, consider doing an NSDR protocol when you wake up. Enter “NSDR” into YouTube and the top 3-4 options have different voices, durations for you to select from. Or simply do a “Yoga Nidra” protocol (enter “yoga nidra” to YouTube; 100s to select.)\n",
    "\n",
    "8) You might consider taking (30-60 min before bed):\n",
    "\n",
    "145mg Magnesium Threonate or 200mg Magnesium Bisglycinate\n",
    "50mg Apigenin\n",
    "100-400mg Theanine\n",
    "(3-4 nights per week I also take 2g of Glycine and 100mg GABA.)\n",
    "*I would start with one supplement (or none!) and then add one at a time as needed. Some people do not need any supplements, and some people like theanine but not magnesium, etc. so you have to determine what is best for you.\n",
    "\n",
    "**Don’t take theanine if you have overly intense dreams, sleep-walk, or have night terrors.\n",
    "\n",
    "***Also, some people (~5%), get an agitated stomach from magnesium supplementation, in which case, do not take it.\n",
    "\n",
    "****I use supplements from Momentous for all of the above. You can get 20% off all Momentous supplements at https://www.livemomentous.com/huberman or you can pick another source you like and trust.\n",
    "\n",
    "9) Expect to feel really alert ~1 hour before your natural bedtime. This is a naturally occurring spike in wakefulness that sleep researchers have observed.\n",
    "\n",
    "Don’t freak out if it happens. It will pass!\n",
    "\n",
    "10) Keep the room you sleep in cool and dark and layer on blankets that you can remove.\n",
    "\n",
    "Your body needs to drop in temperature by 1-3 degrees to fall and stay asleep effectively. Body temperature increases are one reason you wake up. Thus, keep your room cool and remove blankets as needed. If it’s too hot you would have to use a cooling device and that’s harder than simply tossing off blankets if you get too warm.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing functions to evaluate performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RAG Similarity Score': 0.603172833011108, 'Non-RAG Similarity Score': 0.5438751740418429}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - The sentence embedding.\n",
    "    \"\"\"\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    # Generate the sentence embeddings\n",
    "    embeddings = model.encode(text, convert_to_tensor=False)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two embeddings.\n",
    "\n",
    "    Args:\n",
    "    - embedding1 (torch.Tensor): The first embedding.\n",
    "    - embedding2 (torch.Tensor): The second embedding.\n",
    "\n",
    "    Returns:\n",
    "    - The cosine similarity score.\n",
    "    \"\"\"\n",
    "    # Calculate the cosine similarity\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(true_answer, rag_answer, non_rag_answer):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity scores between the true answer and both RAG-based and non-RAG-based answers.\n",
    "\n",
    "    Args:\n",
    "    - true_answer (str): The true answer text.\n",
    "    - rag_answer (str): The RAG-based model's answer text.\n",
    "    - non_rag_answer (str): The non-RAG-based model's answer text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with cosine similarity scores.\n",
    "    \"\"\"\n",
    "    # Convert the answers to embeddings\n",
    "    true_answer_embedding = get_embedding(true_answer)\n",
    "    rag_answer_embedding = get_embedding(rag_answer)\n",
    "    non_rag_answer_embedding = get_embedding(non_rag_answer)\n",
    "    \n",
    "    # Calculate cosine similarity scores\n",
    "    rag_similarity = calculate_cosine_similarity(true_answer_embedding, rag_answer_embedding)\n",
    "    non_rag_similarity = calculate_cosine_similarity(true_answer_embedding, non_rag_answer_embedding)\n",
    "\n",
    "    \n",
    "    # Return the scores\n",
    "    return {\n",
    "        \"RAG Similarity Score\": rag_similarity,\n",
    "        \"Non-RAG Similarity Score\": non_rag_similarity\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate the similarity scores\n",
    "similarity_scores = calculate_similarity_scores(true_answer, rag_answer, non_rag_answer)\n",
    "print(similarity_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
