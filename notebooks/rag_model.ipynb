{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HubermanAI: Using RAG Based LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MONGODB_CONNECTION_STRING = os.getenv(\"MONGODB_URI\")\n",
    "MONGODB_DATABASE = os.getenv(\"MONGODB_DATABASE\")\n",
    "MONGODB_COLLECTION = os.getenv(\"MONGODB_COLLECTION\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction from Newsletter PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Function to preprocess and clean text\n",
    "def preprocess_text_mupdf(text):\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove empty lines\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:!?()\\'\\\"\\n]+', ' ', text)  # Remove special characters but keep punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()\n",
    "\n",
    "# Extract the ZIP file\n",
    "raw_path = '/Users/mrinoyb2/git/Huberman_AI/Data/Raw/Newsletters'\n",
    "clean_text_dir = '/Users/mrinoyb2/git/Huberman_AI/Data/Clean'\n",
    "os.makedirs(clean_text_dir, exist_ok=True)\n",
    "\n",
    "# Process each PDF file in the extracted directory\n",
    "for root, dirs, files in os.walk(raw_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "            cleaned_text_mupdf = \"\"\n",
    "            for page_number in range(pdf_document.page_count):\n",
    "                page = pdf_document.load_page(page_number)\n",
    "                text = page.get_text()\n",
    "                cleaned_text_mupdf += preprocess_text_mupdf(text)\n",
    "\n",
    "            pdf_document.close()\n",
    "\n",
    "            # Save the cleaned text to a corresponding file\n",
    "            clean_text_path = os.path.join(clean_text_dir, os.path.splitext(file)[0] + '.txt')\n",
    "            with open(clean_text_path, 'w') as file:\n",
    "                file.write(cleaned_text_mupdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks in MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mrinoyb2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks stored in MongoDB: 960\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to chunk text by sentence\n",
    "def chunk_by_sentence(text):\n",
    "    \"\"\"\n",
    "    Improved function to chunk text by sentence using NLTK's sent_tokenize.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text to chunk.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of sentences extracted from the input text.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    return [sentence.strip() for sentence in sentences]\n",
    "\n",
    "# Path to the directory containing cleaned text files\n",
    "clean_text_dir = '/Users/mrinoyb2/git/Huberman_AI/Data/Clean'\n",
    "\n",
    "# Initialize a counter for unique MongoDB document IDs\n",
    "doc_id = 0\n",
    "\n",
    "# Iterate through each cleaned text file\n",
    "for file_name in os.listdir(clean_text_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(clean_text_dir, file_name)\n",
    "\n",
    "        # Read the cleaned text from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            cleaned_text = file.read()\n",
    "\n",
    "        # Chunk the text\n",
    "        chunks = chunk_by_sentence(cleaned_text)\n",
    "\n",
    "        # Store chunks in MongoDB\n",
    "        for chunk in chunks:\n",
    "            # Create a document for each chunk\n",
    "            document = {\"_id\": doc_id, \"text\": chunk}\n",
    "            # Insert the document into the collection\n",
    "            collection.insert_one(document)\n",
    "            # Increment the doc_id for the next document\n",
    "            doc_id += 1\n",
    "\n",
    "print(f\"Total chunks stored in MongoDB: {doc_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 0, 'text': '2 9 24, 5:29 PM Using Light for Health Huberman Lab https: www.hubermanlab.com newsletter using light for health 1 11 Neural Network Newsletter Using Light for Health Using Light for Health January 24, 2023 Thank you for joining the Huberman Lab Neural Network a once a month newsletter with science and science related tools for everyday life.', 'embedding': [-0.028163380920886993, -0.015030195005238056, 0.025770673528313637, 0.05299123749136925, 0.050226956605911255, 0.027826806530356407, -0.082654669880867, 0.05679101124405861, -0.031691670417785645, -0.023093437775969505, 0.03952784463763237, 0.001871513668447733, -0.01179493311792612, -0.00349311251193285, -0.03213930502533913, 0.0322083942592144, -0.018941238522529602, -0.03637561947107315, -0.007522422820329666, -0.010602681897580624, -0.009080360643565655, -0.0639241561293602, 0.046462662518024445, -0.015782494097948074, -0.031212473288178444, -0.002136523136869073, 0.05953914299607277, -0.04980574920773506, 0.014285976067185402, 0.02545272372663021, 0.08992312103509903, 0.005933080799877644, -0.01562228798866272, 0.0010339322034269571, -0.05902024358510971, -0.02715320512652397, 0.0335036963224411, -0.060665566474199295, -0.04450389742851257, 0.02559899538755417, -0.002188263926655054, -0.14971362054347992, 0.03238241747021675, -0.010514321736991405, 0.07478432357311249, 0.02114083059132099, -0.028965067118406296, -0.046298008412122726, 0.01686082035303116, -0.014948581345379353, -0.0664718747138977, -0.06965754926204681, 0.037009742110967636, 0.01453104056417942, 0.06476828455924988, 0.07295940071344376, -0.07805811613798141, -0.00778603320941329, 0.03689912334084511, -0.03611377999186516, 0.03621844947338104, -0.007424321491271257, -0.054380692541599274, -0.022952955216169357, 0.06714505702257156, 0.06142726168036461, -0.10724197328090668, 0.01730094850063324, 0.03999274596571922, -0.016178982332348824, -0.024035600945353508, -0.01199343055486679, 0.07764037698507309, 0.008658938109874725, -0.029295343905687332, 0.0327376052737236, 0.04595046862959862, -0.04070953279733658, 0.051954954862594604, -0.08993346244096756, -0.0024706649128347635, 0.008314003236591816, 0.009810220450162888, 0.08902084827423096, 0.06760652363300323, 0.02090754359960556, 0.012640911154448986, 0.14309531450271606, -0.06737518310546875, -0.0600142702460289, -0.030133754014968872, 0.06896352022886276, -0.055287811905145645, 0.01788066141307354, -0.06514755636453629, 0.004925697110593319, -0.007949061691761017, -0.04122091457247734, -0.04056021198630333, 0.012478552758693695, -0.023721180856227875, -0.042618922889232635, -0.06012498959898949, -0.004584205336868763, -0.04197053611278534, -0.028206907212734222, -0.04277414456009865, 0.0880633071064949, 0.01000016275793314, -0.03595740720629692, 0.07195655256509781, 0.023515837267041206, -0.03737684339284897, -0.07289787381887436, 0.035729777067899704, 0.01733923703432083, 0.038051191717386246, -0.02092587947845459, 0.0636410266160965, 0.049005649983882904, 0.014056992717087269, 0.014936587773263454, -0.019008275121450424, -0.037629496306180954, 0.008246256038546562, 0.01802324317395687, 0.06062297895550728, 6.191851840767104e-33, -0.012944420799612999, -0.045818738639354706, 0.009389990009367466, 0.03769764304161072, 0.02865429036319256, -0.0513974092900753, -0.03798671066761017, -0.01968497224152088, -0.009076655842363834, -0.08041626960039139, -0.06237253174185753, 0.03854658082127571, -0.03856012597680092, -0.062054671347141266, -0.11849807947874069, -0.14819258451461792, 0.0599234364926815, 0.04457075148820877, -0.009701602160930634, 0.003508100053295493, -0.02614026516675949, -0.18134206533432007, 0.013567366637289524, 0.04586153104901314, -0.019454792141914368, 0.06727538257837296, 0.050289541482925415, -0.023148370906710625, 0.04404028132557869, 0.03549708425998688, 0.0020000156946480274, 0.07524076104164124, -0.04126924276351929, -0.013828632421791553, -0.00776824401691556, 0.05112667754292488, 0.010083491913974285, 0.03604791313409805, -0.024592451751232147, -0.023757629096508026, -0.004888166207820177, 0.07040649652481079, 0.0571381151676178, -0.030682029202580452, 0.09633715450763702, 0.04125027731060982, 0.002081791404634714, 0.01672050915658474, 0.11619722843170166, -0.03751126676797867, -0.04601942002773285, -0.022478332743048668, -0.05383273586630821, -0.05914110317826271, 0.027079692110419273, 0.04193979501724243, 0.011371197178959846, -0.019289344549179077, 0.007506853435188532, 0.04657736048102379, 0.08407620340585709, 0.03833487257361412, 0.014637567102909088, -0.05358368903398514, 0.004747624043375254, -0.00012701742525678128, -0.034408193081617355, -0.03133438900113106, -0.056404273957014084, 0.028445420786738396, 0.01863825134932995, 0.06013334169983864, -0.028034647926688194, -0.051339805126190186, 0.054178934544324875, 0.017874334007501602, 0.02556726336479187, -0.01906694658100605, -0.10255453735589981, 0.04246002435684204, 0.04479784145951271, 0.004677999764680862, -0.017265474423766136, -0.0009668933344073594, -0.00986110046505928, 0.024864837527275085, -0.042920563369989395, 0.033934347331523895, -0.10709163546562195, -0.04089878126978874, 0.00720632029697299, 0.02970159612596035, 0.08709301799535751, 0.012491924688220024, -0.07384532690048218, -6.003864580131696e-33, -0.012377874925732613, 0.029845166951417923, -0.1059526652097702, 0.05670694634318352, 0.10934363305568695, 0.009357614442706108, -0.01014041155576706, -0.015782305970788002, 0.048750024288892746, 0.14853358268737793, 0.15651637315750122, -0.04017911106348038, -0.10322502255439758, -0.05740517005324364, 0.013122163712978363, 0.01014392077922821, -0.039884645491838455, -0.06789308041334152, -0.0423286035656929, 0.017413169145584106, -0.06141388416290283, 0.04013783857226372, -0.08819589763879776, -0.01980862207710743, -0.04247818887233734, 0.0483640655875206, 0.06124265864491463, 0.08246342092752457, 0.00557031761854887, -0.022476620972156525, -0.14801792800426483, -0.0538300983607769, -0.00768821919336915, 0.047872960567474365, 0.06284361332654953, 0.07853128015995026, 0.060421742498874664, -0.0724041536450386, -0.050334762781858444, 0.00789498258382082, 0.09017372876405716, 0.024464432150125504, -0.13822555541992188, 0.01408512145280838, -0.04516704007983208, 0.011892572976648808, -0.02914750948548317, -0.018816830590367317, -0.06883421540260315, 0.02565077878534794, 0.05946524813771248, -0.04402974620461464, -0.06927695125341415, -0.02438816800713539, -0.03566543012857437, 0.07501205056905746, 0.018687687814235687, 0.04107600077986717, -0.03819473460316658, 0.041629157960414886, -0.02702878788113594, -0.05174800753593445, -0.036614514887332916, 0.03591945394873619, -0.08679959923028946, -0.012526004575192928, 0.06324488669633865, 0.0725584328174591, 0.017487160861492157, 0.016126619651913643, 0.07045876234769821, 0.015188864432275295, 0.015871893614530563, 0.029605994001030922, -0.0014623218448832631, -0.03777201473712921, 0.03721911460161209, 0.03788871690630913, -0.07145056128501892, -0.0013211410259827971, -0.01810496672987938, -0.05215466767549515, 0.037675824016332626, 0.018345778807997704, 0.013793865218758583, -0.022497065365314484, 0.07643264532089233, -0.026155313476920128, -0.07447070628404617, 0.04542399197816849, -0.014871428720653057, 0.03722106292843819, -0.07025761157274246, 0.04617326334118843, -0.008901962079107761, -3.5775414630734304e-08, 0.035667043179273605, -0.06112396717071533, 0.004601303022354841, -0.0034686392173171043, 0.024403557181358337, -0.042931847274303436, 0.05229087173938751, -0.013001917861402035, 0.011816184036433697, 0.07515405863523483, 0.028343776240944862, -0.007238746155053377, -0.0008654380799271166, 0.004102141596376896, 0.021762078627943993, 0.05932658538222313, -0.03614325448870659, -0.03313611447811127, -0.04085730388760567, -0.019204795360565186, -0.02641354128718376, -0.054136380553245544, 0.08608469367027283, -0.04481459781527519, 0.0020975302904844284, 0.04776608198881149, -0.06387642025947571, 0.06741631031036377, 0.02474028989672661, -0.0013800113229081035, 0.10401546955108643, 0.055064864456653595, 0.0229798536747694, -0.03832859918475151, -0.0467655211687088, -0.03423581272363663, -0.07000496238470078, 0.004838387481868267, -0.004148933570832014, 0.15907876193523407, -0.05472448840737343, 0.021950287744402885, -0.0943831205368042, 0.003492612624540925, 0.009294581599533558, -0.0068748691119253635, 0.0023441563826054335, -0.09265237301588058, -0.027709828689694405, 0.07136902958154678, -0.02488371729850769, 0.013163835741579533, 0.04058491811156273, -0.045226335525512695, -0.03548756241798401, 0.04571419954299927, 0.03928247094154358, -0.10049165785312653, -0.08134076744318008, -0.0016484491061419249, 0.055993687361478806, 0.05280438810586929, -0.05070788040757179, 0.04043286293745041]}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to update documents with embeddings\n",
    "def update_documents_with_embeddings():\n",
    "    for document in chunks_collection.find():\n",
    "        # Generate embedding\n",
    "        embedding = model.encode(document['text'], convert_to_tensor=False)\n",
    "        # Update document with embedding\n",
    "        chunks_collection.update_one({'_id': document['_id']}, {'$set': {'embedding': embedding.tolist()}})\n",
    "\n",
    "# Uncomment the following line to run the embedding update\n",
    "update_documents_with_embeddings()\n",
    "\n",
    "# Check the first document to see if the embedding was added\n",
    "print(chunks_collection.find_one())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (Score: 0.611): See Newsletter 1 (Toolkit for Sleep) for details....\n",
      "Result 2 (Score: 0.611): Episode 2 of the Huberman Lab Podcast JMaster Your Sleep) is all about that topic, but I wanted to provide a succinct list of the key things for sleep....\n",
      "Result 3 (Score: 0.567): So whatever your life and goals and schedule, master your sleep....\n",
      "Result 4 (Score: 0.552): I shift to using red lights around 9 p.m., and it has greatly improved my sleep....\n",
      "Result 5 (Score: 0.547): As do most sleep medications....\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to perform semantic search\n",
    "def semantic_search(query, top_k=5):\n",
    "    # Generate query embedding\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = model.encode(query, convert_to_tensor=False)\n",
    "    \n",
    "    # Retrieve all embeddings from MongoDB and calculate similarity\n",
    "    similarities = []\n",
    "    for document in chunks_collection.find():\n",
    "        doc_embedding = np.array(document['embedding'])\n",
    "        # Use scikit-learn's cosine_similarity function to calculate the cosine distance\n",
    "        similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]\n",
    "        # Store document ID and similarity score\n",
    "        similarities.append((document['_id'], similarity, document['text']))\n",
    "    \n",
    "    # Sort by similarity score in descending order\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_k most similar documents\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Example usage\n",
    "query = \"Best sleep protocol?\"\n",
    "results = semantic_search(query)\n",
    "for idx, (doc_id, similarity, text) in enumerate(results, start=1):\n",
    "    print(f\"Result {idx} (Score: {similarity:.3f}): {text}...\")  # Print the first 100 characters for brevity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Gemini Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate an answer using RAG enabled LLama2 from Replicate\n",
    "def generate_RAG_answer(question, max_context_length=1000):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    context_results = semantic_search(question, top_k=5)\n",
    "    # Concatenate the top-k context results into a single string\n",
    "    context = ' '.join([result[2] for result in context_results])\n",
    "    # Truncate context if it exceeds the maximum length\n",
    "    if len(context) > max_context_length:\n",
    "        context = context[:max_context_length]\n",
    "\n",
    "    rag_prompt = f\"[INST]\\nQuestion: {question}\\nContext: {context}\\n[/INST]\"\n",
    "    print(rag_prompt)\n",
    "\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content(rag_prompt)\n",
    "    # return text part of the response\n",
    "    return response.text\n",
    "\n",
    "# Function to generate an answer using LLama2 from Replicate\n",
    "def generate_non_RAG_answer(question):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    non_rag_prompt = f\"[INST]\\nQuestion: {question}\\n[/INST]\"  # Fallback in case no context is found\n",
    "    print(non_rag_prompt)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content(non_rag_prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "Question: You weild the knowledge of Dr. Andrew Huberman. Best sleep protocol?\n",
      "Context: 2 Huberman Lab Podcast, HLP interview w Matt Walker hubermanlab.com Huberman Lab The Huberman Lab podcast discusses science and scie 9 40 PM Sep 15, 2021 2.7K Reply Copy link Read 104 replies2 9 24, 5:33 PM Toolkit for Sleep Huberman Lab https: www.hubermanlab.com newsletter toolkit for sleep 3 10 It ended up being shared more than any other post, which told me that people likely want tools for getting better at sleeping. Enter your email Subscribe2 9 24, 5:33 PM Toolkit for Sleep Huberman Lab https: www.hubermanlab.com newsletter toolkit for sleep 9 10 Thank you for your interest in science In the world s 1 health podcast, Dr. Andrew Huberman explores science and science based tools to help listeners live a healthier, more fulfilling life. What an amazing wealth of2 9 24, 5:33 PM Toolkit for Sleep Huberman Lab https: www.hubermanlab.com newsletter toolkit for sleep 10 10 Podcast Newsletter Topics Constructive Critique Andrew's Routine Become a Member About Premium Log In About FAQ Eve\n",
      "[/INST]\n",
      "**Dr. Andrew Huberman's Optimal Sleep Protocol**\n",
      "\n",
      "**1. Establish a Consistent Sleep-Wake Cycle:**\n",
      "\n",
      "* Go to bed and wake up around the same time each day, even on weekends.\n",
      "* This helps regulate your body's natural sleep-wake cycle (circadian rhythm).\n",
      "\n",
      "**2. Optimize Your Sleep Environment:**\n",
      "\n",
      "* Make your bedroom dark, quiet, and cool.\n",
      "* Use blackout curtains, earplugs, or white noise to minimize distractions.\n",
      "* Keep your bedroom temperature between 60-67°F (15-19°C).\n",
      "\n",
      "**3. Avoid Stimulants Before Bed:**\n",
      "\n",
      "* Limit caffeine and alcohol consumption in the hours leading up to bedtime.\n",
      "* Caffeine can block the effects of sleep-promoting hormones, and alcohol can disrupt sleep quality.\n",
      "\n",
      "**4. Avoid Blue Light Exposure Before Bed:**\n",
      "\n",
      "* Blue light, emitted from electronic devices, can suppress melatonin production and make it harder to fall asleep.\n",
      "* Limit screen time for 2-3 hours before bed or use blue-light blocking glasses.\n",
      "\n",
      "**5. Engage in Relaxing Activities Before Bed:**\n",
      "\n",
      "* Establish a relaxing bedtime routine that promotes sleep, such as reading, taking a warm bath, or listening to calming music.\n",
      "\n",
      "**6. Exercise Regularly:**\n",
      "\n",
      "* Regular physical activity can improve sleep quality, but avoid exercising too close to bedtime as it can raise body temperature and interfere with sleep.\n",
      "\n",
      "**7. Optimize Your Diet:**\n",
      "\n",
      "* Avoid heavy meals or sugary snacks before bed.\n",
      "* Consider consuming foods rich in sleep-promoting compounds, such as tart cherries, bananas, and almonds.\n",
      "\n",
      "**8. Address Underlying Sleep Issues:**\n",
      "\n",
      "* If you experience persistent sleep difficulties, consult a medical professional to rule out any underlying conditions, such as sleep apnea or insomnia.\n",
      "\n",
      "**9. Use Sleep Tracking Devices:**\n",
      "\n",
      "* Track your sleep patterns using sleep trackers or apps to identify any areas for improvement.\n",
      "\n",
      "**10. Practice Mindfulness:**\n",
      "\n",
      "* Engage in mindfulness techniques, such as meditation or deep breathing exercises, to reduce stress and promote relaxation before bed.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"You weild the knowledge of Dr. Andrew Huberman. Best sleep protocol?\"\n",
    "rag_answer = generate_RAG_answer(query)\n",
    "\n",
    "print(rag_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "Question: Best sleep protocol?\n",
      "[/INST]\n",
      "**Best Sleep Protocol**\n",
      "\n",
      "**1. Establish a Regular Sleep-Wake Cycle**\n",
      "\n",
      "* Go to bed and wake up around the same time each day, even on weekends.\n",
      "* This helps regulate your body's natural sleep-wake cycle.\n",
      "\n",
      "**2. Create a Relaxing Bedtime Routine**\n",
      "\n",
      "* Engage in calming activities before bed, such as taking a warm bath, reading, or listening to soothing music.\n",
      "* Avoid screen time (from phones, tablets, or computers) for at least an hour before bed.\n",
      "\n",
      "**3. Optimize Your Sleep Environment**\n",
      "\n",
      "* Make sure your bedroom is dark, quiet, and cool (around 60-67°F).\n",
      "* Use blackout curtains, earplugs, or a white noise machine to minimize distractions.\n",
      "\n",
      "**4. Get Regular Exercise**\n",
      "\n",
      "* Aim for at least 30 minutes of moderate-intensity exercise most days of the week.\n",
      "* However, avoid vigorous exercise close to bedtime, as it can interfere with sleep.\n",
      "\n",
      "**5. Avoid Caffeine and Alcohol Before Bed**\n",
      "\n",
      "* Caffeine and alcohol can disrupt your sleep cycle and make it harder to fall asleep.\n",
      "\n",
      "**6. Set Limits on Napping**\n",
      "\n",
      "* If you need to nap, keep it short (20-30 minutes) and avoid napping late in the afternoon or evening.\n",
      "\n",
      "**7. Use Sleep Aids Wisely**\n",
      "\n",
      "* Over-the-counter sleep aids may help with occasional sleep problems.\n",
      "* However, they should be used sparingly and under the guidance of a healthcare professional.\n",
      "\n",
      "**8. Treat Underlying Sleep Disorders**\n",
      "\n",
      "* If you have a persistent sleep disorder, such as insomnia or sleep apnea, consult a healthcare professional for diagnosis and treatment.\n",
      "\n",
      "**9. Get Enough Sunlight**\n",
      "\n",
      "* Sunlight helps regulate your circadian rhythm, which is essential for good sleep.\n",
      "* Aim for at least 15 minutes of sunlight exposure each day.\n",
      "\n",
      "**10. Seek Professional Help When Needed**\n",
      "\n",
      "* If you consistently struggle with sleep problems that significantly impact your daily life, consider seeking professional help from a doctor or sleep specialist.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Best sleep protocol?\"\n",
    "non_rag_answer = generate_non_RAG_answer(query)\n",
    "\n",
    "print(non_rag_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating RAG vs Non-RAG Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify this, I will take the following steps:\n",
    "1. Think of a query which has a well defined answer in the book.\n",
    "2. Find the true answer to a query from the actual source (book pdf). \n",
    "3. Then pass the query through the RAG based LLM and the regular LLM.\n",
    "4. Save both generated answers along with the true answer and find word embeddings for each. \n",
    "5. Finally, compare the word embeddings of the true answer with the RAG vs Non-RAG based LLM word embeddings using cosine similarity. \n",
    "\n",
    "Following these steps will help quantify the performace and accuracy of information in the two answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Best sleep protocol?\"\n",
    "\n",
    "# True Answer from the Huberman Lab Newsletter\n",
    "true_answer = \"\"\"1) View sunlight by going outside within 30-60 minutes of waking. Do that again in the late afternoon, prior to sunset. If you wake up before the sun is out and you want to be awake, turn on artificial lights and then go outside once the sun rises.\n",
    "\n",
    "On bright cloudless days: view morning and afternoon sun for 10 min; cloudy days: 20 min; very overcast days 30-60 min. If you live someplace with very minimal light, consider an artificial daytime simulator source.\n",
    "\n",
    "Don’t wear sunglasses for this practice if you safely can, but contact lenses and eyeglasses are fine.\n",
    "\n",
    "No, you don’t have to look directly at the sun, and never look at ANY light so bright it is painful to view! That said, you can’t wear a brimmed hat, sunglasses and remain in the shade and expect to “wake up” your circadian clock.\n",
    "​\n",
    "​2) Wake up at the same time each day and go to sleep when you first start to feel sleepy. Pushing through the sleepy late evening feeling and going to sleep too late (for you) is one reason people wake at 3 am and can’t fall back asleep.\n",
    "\n",
    "3) Avoid caffeine within 8-10 hours of bedtime. Dr. Matt Walker (sleep expert from UC Berkeley) might even say 12-14 hours. I do fine with caffeine at 2 pm and I go to sleep at ~10-11 pm. Dr. Walker was on the Huberman Lab Podcast and we discussed this in detail.\n",
    "\n",
    "4) If you have sleep disturbances, insomnia, or anxiety about sleep, try the research-supported protocols on the Reveri app (for iPhone). Do the Reveri sleep self-hypnosis 3x a week at any time of day. It’s only 10-15 min long and will help you rewire your nervous system to be able to relax faster.\n",
    "\n",
    "5) Avoid viewing bright lights—especially bright overhead lights between 10 pm and 4 am. Here is a simple rule: only use as much artificial lighting as is necessary for you to remain and move about safely at night. Blue blockers can help a bit at night but still dim the lights. Viewing bright lights of all colors are a problem for your circadian system. Candlelight and moonlight are fine. (Shift workers should see the Huberman Lab Podcast on jetlag for offsetting shift work negative effects. Same for jetlagged travelers.)\n",
    "\n",
    "6) Limit daytime naps to less than 90 min, or don’t nap at all. I love naps as do many of my colleagues. I tend to nap for 30 min most afternoons… maybe 45 min, but never longer.\n",
    "\n",
    "7) If you wake up in the middle of the night (which, by the way, is normal to do once or so each night) but you can’t fall back asleep, consider doing an NSDR protocol when you wake up. Enter “NSDR” into YouTube and the top 3-4 options have different voices, durations for you to select from. Or simply do a “Yoga Nidra” protocol (enter “yoga nidra” to YouTube; 100s to select.)\n",
    "\n",
    "8) You might consider taking (30-60 min before bed):\n",
    "\n",
    "145mg Magnesium Threonate or 200mg Magnesium Bisglycinate\n",
    "50mg Apigenin\n",
    "100-400mg Theanine\n",
    "(3-4 nights per week I also take 2g of Glycine and 100mg GABA.)\n",
    "*I would start with one supplement (or none!) and then add one at a time as needed. Some people do not need any supplements, and some people like theanine but not magnesium, etc. so you have to determine what is best for you.\n",
    "\n",
    "**Don’t take theanine if you have overly intense dreams, sleep-walk, or have night terrors.\n",
    "\n",
    "***Also, some people (~5%), get an agitated stomach from magnesium supplementation, in which case, do not take it.\n",
    "\n",
    "****I use supplements from Momentous for all of the above. You can get 20% off all Momentous supplements at https://www.livemomentous.com/huberman or you can pick another source you like and trust.\n",
    "\n",
    "9) Expect to feel really alert ~1 hour before your natural bedtime. This is a naturally occurring spike in wakefulness that sleep researchers have observed.\n",
    "\n",
    "Don’t freak out if it happens. It will pass!\n",
    "\n",
    "10) Keep the room you sleep in cool and dark and layer on blankets that you can remove.\n",
    "\n",
    "Your body needs to drop in temperature by 1-3 degrees to fall and stay asleep effectively. Body temperature increases are one reason you wake up. Thus, keep your room cool and remove blankets as needed. If it’s too hot you would have to use a cooling device and that’s harder than simply tossing off blankets if you get too warm.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing functions to evaluate performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RAG Similarity Score': 0.603172833011108, 'Non-RAG Similarity Score': 0.5438751740418429}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate an embedding for a given text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - The sentence embedding.\n",
    "    \"\"\"\n",
    "    # Load the sentence transformer model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    # Generate the sentence embeddings\n",
    "    embeddings = model.encode(text, convert_to_tensor=False)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two embeddings.\n",
    "\n",
    "    Args:\n",
    "    - embedding1 (torch.Tensor): The first embedding.\n",
    "    - embedding2 (torch.Tensor): The second embedding.\n",
    "\n",
    "    Returns:\n",
    "    - The cosine similarity score.\n",
    "    \"\"\"\n",
    "    # Calculate the cosine similarity\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(true_answer, rag_answer, non_rag_answer):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity scores between the true answer and both RAG-based and non-RAG-based answers.\n",
    "\n",
    "    Args:\n",
    "    - true_answer (str): The true answer text.\n",
    "    - rag_answer (str): The RAG-based model's answer text.\n",
    "    - non_rag_answer (str): The non-RAG-based model's answer text.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with cosine similarity scores.\n",
    "    \"\"\"\n",
    "    # Convert the answers to embeddings\n",
    "    true_answer_embedding = get_embedding(true_answer)\n",
    "    rag_answer_embedding = get_embedding(rag_answer)\n",
    "    non_rag_answer_embedding = get_embedding(non_rag_answer)\n",
    "    \n",
    "    # Calculate cosine similarity scores\n",
    "    rag_similarity = calculate_cosine_similarity(true_answer_embedding, rag_answer_embedding)\n",
    "    non_rag_similarity = calculate_cosine_similarity(true_answer_embedding, non_rag_answer_embedding)\n",
    "\n",
    "    \n",
    "    # Return the scores\n",
    "    return {\n",
    "        \"RAG Similarity Score\": rag_similarity,\n",
    "        \"Non-RAG Similarity Score\": non_rag_similarity\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate the similarity scores\n",
    "similarity_scores = calculate_similarity_scores(true_answer, rag_answer, non_rag_answer)\n",
    "print(similarity_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
